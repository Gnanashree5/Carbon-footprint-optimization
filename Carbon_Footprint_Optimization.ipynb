{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU9xv3DCsqwG",
        "outputId": "31c6ebea-9030-4df5-f3b3-9a45fd152561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8296.5566 - mae: 79.4565 - val_loss: 7807.1353 - val_mae: 79.0430\n",
            "Epoch 2/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7880.5864 - mae: 77.2907 - val_loss: 6653.3389 - val_mae: 72.3093\n",
            "Epoch 3/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6417.4800 - mae: 67.7593 - val_loss: 4295.8892 - val_mae: 57.0297\n",
            "Epoch 4/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4045.3159 - mae: 52.8071 - val_loss: 1584.8873 - val_mae: 33.7382\n",
            "Epoch 5/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1382.3621 - mae: 30.7323 - val_loss: 272.0434 - val_mae: 14.1184\n",
            "Epoch 6/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.6744 - mae: 14.5258 - val_loss: 128.7931 - val_mae: 8.7886\n",
            "Epoch 7/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.1240 - mae: 10.2149 - val_loss: 102.6793 - val_mae: 7.8005\n",
            "Epoch 8/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.5327 - mae: 8.9801 - val_loss: 91.7735 - val_mae: 7.3400\n",
            "Epoch 9/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.4858 - mae: 8.8100 - val_loss: 87.3970 - val_mae: 7.1480\n",
            "Epoch 10/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.4749 - mae: 7.8523 - val_loss: 85.3260 - val_mae: 7.1126\n",
            "Epoch 11/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95.6017 - mae: 7.6734 - val_loss: 82.9508 - val_mae: 7.0352\n",
            "Epoch 12/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90.8755 - mae: 7.4997 - val_loss: 81.3508 - val_mae: 6.9742\n",
            "Epoch 13/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.0832 - mae: 7.4092 - val_loss: 78.4927 - val_mae: 6.8236\n",
            "Epoch 14/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.2764 - mae: 7.1089 - val_loss: 76.4795 - val_mae: 6.7399\n",
            "Epoch 15/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 78.4872 - mae: 7.0466 - val_loss: 73.8867 - val_mae: 6.6484\n",
            "Epoch 16/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 76.0158 - mae: 6.8163 - val_loss: 70.2861 - val_mae: 6.4722\n",
            "Epoch 17/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.6843 - mae: 7.2179 - val_loss: 67.6779 - val_mae: 6.3482\n",
            "Epoch 18/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.4491 - mae: 6.8382 - val_loss: 65.2324 - val_mae: 6.2027\n",
            "Epoch 19/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.3863 - mae: 6.6596 - val_loss: 62.6605 - val_mae: 6.0878\n",
            "Epoch 20/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.5183 - mae: 6.7358 - val_loss: 59.5077 - val_mae: 5.9746\n",
            "Epoch 21/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.0617 - mae: 6.2215 - val_loss: 56.3290 - val_mae: 5.8094\n",
            "Epoch 22/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.4276 - mae: 6.1814 - val_loss: 53.0613 - val_mae: 5.6161\n",
            "Epoch 23/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.1402 - mae: 5.8380 - val_loss: 50.5268 - val_mae: 5.4872\n",
            "Epoch 24/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.8088 - mae: 5.6728 - val_loss: 47.1941 - val_mae: 5.3205\n",
            "Epoch 25/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.0043 - mae: 5.5596 - val_loss: 44.4395 - val_mae: 5.1119\n",
            "Epoch 26/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.5496 - mae: 5.4966 - val_loss: 41.3097 - val_mae: 4.9517\n",
            "Epoch 27/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.4021 - mae: 5.3931 - val_loss: 38.1389 - val_mae: 4.7524\n",
            "Epoch 28/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.1512 - mae: 4.7976 - val_loss: 36.0109 - val_mae: 4.6327\n",
            "Epoch 29/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.9381 - mae: 4.9390 - val_loss: 33.4525 - val_mae: 4.4254\n",
            "Epoch 30/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.0321 - mae: 4.6933 - val_loss: 30.0334 - val_mae: 4.2130\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\n",
            "MAE: 4.47 kg CO₂\n",
            "RMSE: 5.57 kg CO₂\n",
            "Percentage Error: 12.50%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\n",
            "Route Suggestions with Predicted Emissions:\n",
            "   distance  cargo_weight  traffic_level  temperature  fuel_used  \\\n",
            "0       100          1200              1           30         15   \n",
            "1       110          1300              2           32         17   \n",
            "2        90          1250              0           28         13   \n",
            "\n",
            "   predicted_emission  \n",
            "0           34.271248  \n",
            "1           37.950798  \n",
            "2           36.627991  \n",
            "\n",
            "✅ Recommended Greenest Route:\n",
            "distance               100.000000\n",
            "cargo_weight          1200.000000\n",
            "traffic_level            1.000000\n",
            "temperature             30.000000\n",
            "fuel_used               15.000000\n",
            "predicted_emission      34.271248\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Step 2: Simulate Sample Dataset (or load real dataset)\n",
        "# Features: distance(km), cargo_weight(kg), traffic_level(0-3), temperature(C), fuel_consumed(litres)\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'distance': np.random.uniform(10, 500, 1000),\n",
        "    'cargo_weight': np.random.uniform(200, 5000, 1000),\n",
        "    'traffic_level': np.random.randint(0, 4, 1000),\n",
        "    'temperature': np.random.uniform(10, 40, 1000),\n",
        "    'fuel_used': np.random.uniform(2, 60, 1000)\n",
        "})\n",
        "\n",
        "# Target: carbon_emission (in kg CO₂) [Assume 2.68 kg CO₂ per litre of diesel]\n",
        "data['carbon_emission'] = data['fuel_used'] * 2.68\n",
        "\n",
        "# Step 3: Split Data\n",
        "X = data.drop('carbon_emission', axis=1)\n",
        "y = data['carbon_emission']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
        "\n",
        "# Step 4: Define Deep Learning Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)  # output: predicted carbon emission\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Step 5: Train Model\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.1)\n",
        "\n",
        "# Step 6: Evaluate Model\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "percent_error = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(f\"\\nMAE: {mae:.2f} kg CO₂\")\n",
        "print(f\"RMSE: {rmse:.2f} kg CO₂\")\n",
        "print(f\"Percentage Error: {percent_error:.2f}%\")\n",
        "\n",
        "# Step 7: Eco Route Suggestion Example\n",
        "# Let's simulate 3 route options\n",
        "routes = pd.DataFrame({\n",
        "    'distance': [100, 110, 90],\n",
        "    'cargo_weight': [1200, 1300, 1250],\n",
        "    'traffic_level': [1, 2, 0],\n",
        "    'temperature': [30, 32, 28],\n",
        "    'fuel_used': [15, 17, 13]  # estimated fuel used\n",
        "})\n",
        "\n",
        "routes_scaled = scaler.transform(routes)\n",
        "emissions = model.predict(routes_scaled).flatten()\n",
        "\n",
        "# Add prediction to route table\n",
        "routes['predicted_emission'] = emissions\n",
        "best_route = routes.loc[routes['predicted_emission'].idxmin()]\n",
        "\n",
        "print(\"\\nRoute Suggestions with Predicted Emissions:\")\n",
        "print(routes)\n",
        "\n",
        "print(\"\\n✅ Recommended Greenest Route:\")\n",
        "print(best_route)\n"
      ]
    }
  ]
}